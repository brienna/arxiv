{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo download\n",
    "\n",
    "I need to redo all of my downloads, because I had been doing it wrong. So this notebook does that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "2. Download tars based on metadata.\n",
    "    - If tars exist on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import boto3, configparser, os, pandas as pd, shutil\n",
    "import datetime, urllib, numpy as np, tarfile, gzip\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_bulk_metadata(date_of_last_request):  \n",
    "    rows = []\n",
    "    resumptionToken = 'placeholder'\n",
    "    url = 'http://export.arxiv.org/oai2?verb=ListRecords&set=physics:astro-ph&metadataPrefix=arXiv'\n",
    "    \n",
    "    # If we have specified the date of the last request, add it to the URL\n",
    "    if date_of_last_request:\n",
    "        url += '&from=' + date_of_last_request.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Continue requesting until we are not given any more resumption tokens\n",
    "    while resumptionToken is not None:\n",
    "        # Send request and receive results\n",
    "        print('Requesting: ' + url)\n",
    "        results = urllib.request.urlopen(url).read()\n",
    "\n",
    "        # Parse with Beautiful Soup\n",
    "        soup = BeautifulSoup(results, 'xml')\n",
    "        records = soup.find_all('record')\n",
    "        for record in records:\n",
    "            # Get header data\n",
    "            identifier = record.find('identifier')\n",
    "            datestamp = record.find('datestamp')\n",
    "            spec = record.find('setSpec')\n",
    "\n",
    "            # Get metadata\n",
    "            filename = record.find('id')\n",
    "            created = record.find('created')\n",
    "            updated = record.find('updated')\n",
    "            authors = []\n",
    "            for author in record.find_all('author'):\n",
    "                forenames = author.forenames\n",
    "                keyname = author.keyname\n",
    "                if forenames and keyname:\n",
    "                    authors.append(author.forenames.text.strip() + ' ' + author.keyname.text.strip())\n",
    "            author_str = ', '.join(authors)\n",
    "            title = record.find('title')\n",
    "            categories = record.find('categories')\n",
    "            journal = record.find('journal-ref')\n",
    "            doi = record.find('doi')\n",
    "            abstract = record.find('abstract')\n",
    "            comments = record.find('comment')\n",
    "\n",
    "            # Save current record as a row in the table\n",
    "            row = {\n",
    "                'identifier': getattr(identifier, 'text', None),\n",
    "                'filename': getattr(filename, 'text', None),\n",
    "                'spec': getattr(spec, 'text', None),\n",
    "                'title': getattr(title, 'text', None),\n",
    "                'datestamp': getattr(datestamp, 'text', None),\n",
    "                'created': getattr(created, 'text', None),\n",
    "                'updated': getattr(updated, 'text', None), # may have more than one instance that we're missing\n",
    "                'authors': author_str,\n",
    "                'categories': getattr(categories, 'text', None),\n",
    "                'journal': getattr(journal, 'text', None),\n",
    "                'doi': getattr(doi, 'text', None),\n",
    "                'abstract': getattr(abstract, 'text', None),\n",
    "                'comments': getattr(comments, 'text', None)\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "        # Get resumption token if provided\n",
    "        resumptionToken = soup.find('resumptionToken')\n",
    "\n",
    "        # Continue if we have resumption token\n",
    "        if resumptionToken is not None:\n",
    "            print('Status: ' + str(int(resumptionToken['cursor']) + 1) + 'â€”' + str(len(rows)) + '/' + str(resumptionToken['completeListSize']) + '...')\n",
    "            resumptionToken = resumptionToken.text\n",
    "            url = 'http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=' + resumptionToken\n",
    "            time.sleep(20) # avoid 503 status\n",
    "        else:\n",
    "            # Otherwise, obtain date of last request and the while loop ends here\n",
    "            requestDate = soup.find('responseDate').text\n",
    "        \n",
    "    return rows, requestDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_metadata_astroph.csv last updated on 2019-02-21\n",
      "Updating...\n",
      "Requesting: http://export.arxiv.org/oai2?verb=ListRecords&set=physics:astro-ph&metadataPrefix=arXiv&from=2019-02-22\n",
      "No additional records found. Metadata is up to date.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0704.0009\n",
       "1         0704.0017\n",
       "2         0704.0023\n",
       "3         0704.0044\n",
       "4         0704.0048\n",
       "5         0704.0059\n",
       "6         0704.0080\n",
       "7         0704.0094\n",
       "8         0704.0128\n",
       "9         0704.0133\n",
       "10        0704.0138\n",
       "11        0704.0139\n",
       "12        0704.0144\n",
       "13        0704.0155\n",
       "14        0704.0156\n",
       "15        0704.0160\n",
       "16        0704.0168\n",
       "17        0704.0171\n",
       "18        0704.0175\n",
       "19        0704.0184\n",
       "20        0704.0187\n",
       "21        0704.0192\n",
       "22        0704.0203\n",
       "23        0704.0205\n",
       "24        0704.0207\n",
       "25        0704.0209\n",
       "26        0704.0212\n",
       "27        0704.0219\n",
       "28        0704.0221\n",
       "29        0704.0222\n",
       "            ...    \n",
       "251231    0705.0889\n",
       "251232    0705.0894\n",
       "251233    0705.0898\n",
       "251234    0705.0905\n",
       "251235    0705.0910\n",
       "251236    0705.0913\n",
       "251237    0705.0914\n",
       "251238    0705.0918\n",
       "251239    0705.0919\n",
       "251240    0705.0922\n",
       "251241    0705.0935\n",
       "251242    0705.0940\n",
       "251243    0705.0963\n",
       "251244    0705.0966\n",
       "251245    0705.0971\n",
       "251246    0705.0973\n",
       "251247    0705.0977\n",
       "251248    0705.0978\n",
       "251249    0705.0979\n",
       "251250    0705.0981\n",
       "251251    0705.0986\n",
       "251252    0705.0987\n",
       "251253    0705.0988\n",
       "251254    0705.0993\n",
       "251255    0705.0996\n",
       "251256    0705.1006\n",
       "251257    0705.1007\n",
       "251258    0705.1010\n",
       "251259    0705.1011\n",
       "251260    0705.1015\n",
       "Name: filename_parsed, Length: 251261, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global metadata_filepath\n",
    "global identifiers\n",
    "metadata_filepath = 'arxiv_metadata_astroph.csv'\n",
    "\n",
    "if os.path.exists(metadata_filepath):\n",
    "    # If the metadata file exists, load it into a data frame\n",
    "    existing_metadata_df = pd.read_csv(metadata_filepath, \n",
    "                                       dtype={'filename': str,\n",
    "                                              'filename_parsed': str,\n",
    "                                              'identifier': str,\n",
    "                                              'updated': str,\n",
    "                                              'doi': str}, \n",
    "                                       parse_dates=['date_retrieved'])\n",
    "    # Get the date of the last request\n",
    "    date_of_last_request = existing_metadata_df['date_retrieved'].max()\n",
    "    print(metadata_filepath + ' last updated on ' + date_of_last_request.strftime('%Y-%m-%d'))\n",
    "    print('Updating...')\n",
    "    # Send a request to access metadata since that date\n",
    "    records, requestDate = request_bulk_metadata(date_of_last_request + datetime.timedelta(days=1))\n",
    "    # Create data frame for records to specify additional info\n",
    "    if len(records) > 0:\n",
    "        print('Number of new records found: ' + str(len(records)))\n",
    "        records_df = pd.DataFrame(records)\n",
    "        records_df['date_retrieved'] = np.full(len(records_df), requestDate)\n",
    "        records_df['filename_parsed'] = existing_metadata_df['filename'].str.replace('/', '')\n",
    "        # Update metadata file\n",
    "        metadata_df = pd.concat([existing_metadata_df, records_df], axis=0, sort=True, ignore_index=True)\n",
    "        metadata_df.to_csv(metadata_filepath, index=False)\n",
    "        print('Metadata has been updated.')\n",
    "    else: \n",
    "        print('No additional records found. Metadata is up to date.')\n",
    "else:\n",
    "    # If the metadata file doesn't exist, request all metadata\n",
    "    print(metadata_filepath + ' is being created...')\n",
    "    records, requestDate = request_bulk_metadata(None)\n",
    "    # Load records into data frame\n",
    "    metadata_df = pd.DataFrame(records)\n",
    "    # Add a column to specify additional info\n",
    "    metadata_df['date_retrieved'] = np.full(len(metadata_df), requestDate)\n",
    "    metadata_df['filename_parsed'] = metadata_df['filename'].str.replace('/', '')\n",
    "    # Save it to CSV\n",
    "    metadata_df.to_csv(metadata_filepath, index=False)\n",
    "    print('Metadata has been saved.')\n",
    "    \n",
    "# Grab identifiers \n",
    "metadata_df = pd.read_csv(metadata_filepath, \n",
    "                           dtype={'filename': str,\n",
    "                                  'filename_parsed': str,\n",
    "                                  'identifier': str,\n",
    "                                  'updated': str,\n",
    "                                  'doi': str}, \n",
    "                           parse_dates=['date_retrieved'])\n",
    "identifiers = metadata_df['filename_parsed']\n",
    "identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Google Drive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Google Drive to see which tars we have stored ourselves (to save $):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=205689913441-4qvumj04tvu7o2h0j1cth62qhp0ck9ld.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "# Set up Google Drive according to docs\n",
    "def connect_to_google_drive():\n",
    "    g_login = GoogleAuth()\n",
    "    g_login.LocalWebserverAuth()\n",
    "    drive = GoogleDrive(g_login)\n",
    "    return drive\n",
    "\n",
    "drive = connect_to_google_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_gdrive_file(file, title):\n",
    "    '''\n",
    "    Downloads given file from Google Drive.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        The file in the form of a GoogleFile object \n",
    "    title : str\n",
    "        The filename of the file\n",
    "    '''\n",
    "        \n",
    "    # Ensure src directory exists \n",
    "    if not os.path.isdir('src'):\n",
    "        os.makedirs('src')\n",
    "    \n",
    "    # Download file\n",
    "    print('Downloading ' + title + '...')\n",
    "    file.GetContentFile(title) \n",
    "    print('Successfully downloaded drive://arxiv/{} to {}'.format(os.path.basename(title), title))\n",
    "    \n",
    "\n",
    "def query_tarfiles_from_arxiv_folder_on_gdrive(key):\n",
    "    '''\n",
    "    Gets names of all tarfiles in arxiv folder on Google Drive. \n",
    "    Returns list of strings, each string representing a name. \n",
    "    If there is no folder or it is empty, an empty list is returned. \n",
    "    '''\n",
    "    \n",
    "    gdrive_tars = []\n",
    "    query = \"'root' in parents and trashed=false and title='arxiv' and mimeType='application/vnd.google-apps.folder'\"\n",
    "    arxiv_folder_id = drive.ListFile({'q': query}).GetList()[0].metadata['id']\n",
    "    \n",
    "    # If folder doesn't exist, create and upload it, exit (we will have to query everything from S3)\n",
    "    if not arxiv_folder_id:\n",
    "        print('Google Drive does not contain a folder named \\'arxiv\\'. Creating folder...')\n",
    "        arxiv_folder = drive.CreateFile({'title': 'arxiv', \n",
    "                                    \"mimeType\": \"application/vnd.google-apps.folder\"}) \n",
    "        arxiv_folder.Upload()\n",
    "        arxiv_folder_id = arxiv_folder['id']\n",
    "        print('Folder created.')\n",
    "    else:\n",
    "        # Get list of files in arxiv folder\n",
    "        gdrive_tars = drive.ListFile({'q': \"'\" + arxiv_folder_id + \"' in parents and trashed=false\"}).GetList()\n",
    "        gdrive_tars_str = [x.metadata['title'] for x in gdrive_tars]\n",
    "        print('Number of tars on Google Drive: ' + str(len(gdrive_tars)))\n",
    "        gdrive_tars_str.sort()\n",
    "    \n",
    "    return gdrive_tars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tars on Google Drive: 1388\n"
     ]
    }
   ],
   "source": [
    "gdrive_tars = query_tarfiles_from_arxiv_folder_on_gdrive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_preprints(folder):\n",
    "    '''\n",
    "    Collects the filepaths for all preprints within \n",
    "    the given folder. Returns an array of strings,\n",
    "    each string representing the path of a preprint.\n",
    "    '''\n",
    "    \n",
    "    # Initialize variables\n",
    "    global empty_submissions \n",
    "    empty_submissions = []\n",
    "    global preprints \n",
    "    preprints = []\n",
    "    global corrupt_submissions \n",
    "    corrupt_submissions = []\n",
    "    base_path = folder\n",
    "    submission_count = 0\n",
    "    texfile_count = 0\n",
    "\n",
    "    # Walk through tar directories\n",
    "    for idx, tar_folder in enumerate(os.listdir(base_path)):\n",
    "        \n",
    "        # If current path isn't a directory, skip\n",
    "        tar_path = base_path + '/' + tar_folder\n",
    "        if not os.path.isdir(tar_path):\n",
    "            continue\n",
    "        \n",
    "        # Walk through each submission directory\n",
    "        submission_dirs = os.listdir(tar_path)\n",
    "        submission_count += len(submission_dirs)\n",
    "        for submission in submission_dirs:\n",
    "            \n",
    "            # If current path isn't a directory, skip\n",
    "            submission_path = tar_path + '/' + submission\n",
    "            if not os.path.isdir(submission_path):\n",
    "                submission_count -= 1\n",
    "                continue\n",
    "\n",
    "            arxiv_id = os.path.basename(submission_path) # used to note empty or corrupt submissions \n",
    "\n",
    "            # If submission is empty, note & skip\n",
    "            texs = glob.glob(submission_path + '/**/*.tex', recursive=True)\n",
    "            texfile_count += len(texs)\n",
    "            if len(texs) == 0:\n",
    "                empty_submissions.append(arxiv_id)\n",
    "                continue\n",
    "            \n",
    "            # Otherwise get the preprint\n",
    "            else:\n",
    "                preprint_path = identify_preprint(submission_path, texs)\n",
    "                if preprint_path:\n",
    "                    preprints.append(preprint_path)\n",
    "                else:\n",
    "                    corrupt_submissions.append(arxiv_id)\n",
    "    \n",
    "    print('TEX files: ' + str(texfile_count))\n",
    "    print('Submissions: ' + str(submission_count))\n",
    "    print('Preprints: ' + str(len(preprints)))\n",
    "    print('Empty submissions: ' + str(len(empty_submissions)))\n",
    "    print('Potentially corrupt submissions: ' + str(len(corrupt_submissions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "global s3resource \n",
    "\n",
    "def setup():\n",
    "    '''\n",
    "    Creates S3 resource & sets configs to enable download.\n",
    "    '''\n",
    "\n",
    "    # Securely import configs from private AWS config file\n",
    "    configs = configparser.ConfigParser()\n",
    "    configs.read('config.ini')\n",
    "\n",
    "    # Create S3 resource & set configs\n",
    "    global s3resource\n",
    "    s3resource = boto3.resource(\n",
    "        's3',  # the AWS resource we want to use\n",
    "        aws_access_key_id=configs['DEFAULT']['ACCESS_KEY'],\n",
    "        aws_secret_access_key=configs['DEFAULT']['SECRET_KEY'],\n",
    "        region_name='us-east-1'  # same region the arxiv bucket is in\n",
    "    )\n",
    "\n",
    "def start():\n",
    "    '''\n",
    "    Queries S3 arxiv bucket to see which tar files to download,\n",
    "    and calls download_file() on the appropriate tar files. \n",
    "    '''\n",
    "    \n",
    "    print('Querying S3 arxiv bucket...')\n",
    "    setup()\n",
    "\n",
    "    # Create a reusable Paginator\n",
    "    paginator = s3resource.meta.client.get_paginator('list_objects_v2')\n",
    "\n",
    "    # Create a PageIterator from the Paginator\n",
    "    page_iterator = paginator.paginate(\n",
    "        Bucket='arxiv',\n",
    "        RequestPayer='requester',\n",
    "        Prefix='src/'\n",
    "    )\n",
    "\n",
    "    # Download and extract tars\n",
    "    numFiles = 0\n",
    "    gdrive_tar = None\n",
    "    for page in page_iterator:\n",
    "        numFiles = numFiles + len(page['Contents'])\n",
    "        for file in page['Contents']:\n",
    "            key = file['Key']\n",
    "            # If current file is a tar \n",
    "            if key.endswith('.tar'):\n",
    "                # Check if file exists in Google Drive \n",
    "                for google_file in gdrive_tars:\n",
    "                    if google_file.metadata['title'] == os.path.basename(key):\n",
    "                        gdrive_tar = google_file\n",
    "                        break\n",
    "                # If it is in Google Drive, download it, extract, convert, delete\n",
    "                if gdrive_tar:\n",
    "                    download_gdrive_file(gdrive_tar, key)\n",
    "                    extract(key)\n",
    "                    # Convert... [needed]\n",
    "                    os.remove(key)\n",
    "                # Otherwise download it from S3\n",
    "                else:\n",
    "                    download_file(key)\n",
    "                    extract(key)\n",
    "                    # Convert... [needed]\n",
    "                    # Upload .tar to Google Drive for storage\n",
    "                    os.remove(key)\n",
    "            \n",
    "    print('Processed ' + str(numFiles - 1) + ' tars')  # -1 \n",
    "    \n",
    "def download_file(key):\n",
    "    '''\n",
    "    Downloads given filename from source bucket to destination directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        Name of file to download\n",
    "    '''\n",
    "\n",
    "    # Ensure src directory exists \n",
    "    if not os.path.isdir('src'):\n",
    "        os.makedirs('src')\n",
    "    \n",
    "    print('Downloading s3://arxiv/{}'.format(key))\n",
    "    \n",
    "    # Download file\n",
    "    try:\n",
    "        s3resource.meta.client.download_file(\n",
    "            Bucket='arxiv', \n",
    "            Key=key,  # name of key to download from\n",
    "            Filename=key,  # path to file to download to\n",
    "            ExtraArgs={'RequestPayer':'requester'})\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print('ERROR: ' + key + \" does not exist in arxiv bucket\")\n",
    "            \n",
    "    print('Successfully downloaded s3://arxiv/{} to {}'.format(key, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying S3 arxiv bucket...\n",
      "Downloading src/arXiv_src_0001_001.tar...\n",
      "Successfully downloaded drive://arxiv/arXiv_src_0001_001.tar to src/arXiv_src_0001_001.tar\n",
      "Opening src/arXiv_src_0001_001.tar\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gzip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-85ba4973bfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-81b382131d16>\u001b[0m in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgdrive_tar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0mdownload_gdrive_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdrive_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0;31m# Convert... [needed]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-0a5ed8687777>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midentifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mbasename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbasename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gzip' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll need to log which astrophysics articles are in which tars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(filepath):\n",
    "    '''\n",
    "    Extracts astro-ph submissions from given tar filepath.\n",
    "    '''\n",
    "    \n",
    "    global identifiers \n",
    "    \n",
    "    # Quit file extraction if given file is not tarfile\n",
    "    if not tarfile.is_tarfile(filepath):\n",
    "        print('can\\'t unzip {}, not a .tar file'.format(filepath))\n",
    "    \n",
    "    total_tex = 0\n",
    "    tar_dir = 'latex/' + os.path.splitext(os.path.basename(filepath))[0] + '/'\n",
    "\n",
    "    # Create .tar directory if it doesn't exist\n",
    "    if not os.path.isdir(tar_dir):\n",
    "        os.makedirs(tar_dir)\n",
    "        \n",
    "    # Open tarfile, read-only\n",
    "    print('Opening {}'.format(filepath))\n",
    "    tar = tarfile.open(filepath)\n",
    "    # Iterate over submissions, extracting only those that belong to the astro-ph category\n",
    "    for submission in tar.getmembers():\n",
    "        # Create submission directory if it doesn't exist\n",
    "        submission_id = os.path.splitext(os.path.basename(submission.name))[0]\n",
    "        submission_path = tar_dir + '/' + submission_id\n",
    "        if submission.name.endswith('.gz') and identifiers.str.contains(submission_id).any():\n",
    "            if not os.path.isdir(submission_path):\n",
    "                os.makedirs(submission_path)\n",
    "            #### Extract here.........\n",
    "            try:\n",
    "                gz_obj = tar.extractfile(submission) \n",
    "                gz = tarfile.open(fileobj=gz_obj) \n",
    "                gz.extractall(path=submission_path)\n",
    "                total_tex += 1\n",
    "            except tarfile.ReadError:\n",
    "                # Extract the entire .gz because we cannot read it using tarfile \n",
    "                # Note that these .gzs are single .tex files with no extension specified\n",
    "                tar.extract(submission, path='temp')\n",
    "                # Uncompress the .gz file using gzip instead and place it with the other .tex files\n",
    "                with gzip.open('temp/' + submission.name, 'rb') as f_in:\n",
    "                    basename = os.path.splitext(os.path.basename(submission.name))[0]\n",
    "                    with open(tar_dir + submission_id + '/' + basename + '.tex', 'wb+') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "                        total_tex += 1\n",
    "    tar.close()\n",
    "    \n",
    "    print(filepath + ' extraction complete')\n",
    "    print('Number of .tex files obtained: ' + str(total_tex) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying S3 arxiv bucket...\n",
      "Downloading src/arXiv_src_0001_001.tar...\n",
      "Successfully downloaded drive://arxiv/arXiv_src_0001_001.tar to src/arXiv_src_0001_001.tar\n",
      "Opening src/arXiv_src_0001_001.tar\n",
      "src/arXiv_src_0001_001.tar extraction complete\n",
      "Number of .tex files obtained: 600\n",
      "\n",
      "Downloading src/arXiv_src_0002_001.tar...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 49] Can't assign requested address",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-85ba4973bfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-81b382131d16>\u001b[0m in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# If it is in Google Drive, download it, extract, convert, delete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgdrive_tar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                     \u001b[0mdownload_gdrive_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdrive_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                     \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0;31m# Convert... [needed]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-2add3fd12ef8>\u001b[0m in \u001b[0;36mdownload_gdrive_file\u001b[0;34m(file, title)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Download file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Successfully downloaded drive://arxiv/{} to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentFile\u001b[0;34m(self, filename, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchContent\u001b[0;34m(self, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mexport_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exportLinks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DownloadFromUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServiceAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalWebserverAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Initialise service if not built yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess_token_expired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m           \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydrive/auth.py\u001b[0m in \u001b[0;36mRefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttplib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAccessTokenRefreshError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRefreshError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Access token refresh failed: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/client.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, http)\u001b[0m\n\u001b[1;32m    543\u001b[0m                   \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrevoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/client.py\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self, http)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \"\"\"\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_refresh_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/client.py\u001b[0m in \u001b[0;36m_do_refresh_request\u001b[0;34m(self, http)\u001b[0m\n\u001b[1;32m    778\u001b[0m         resp, content = transport.request(\n\u001b[1;32m    779\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             body=body, headers=headers)\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhttp_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(http, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    280\u001b[0m     return http_callable(uri, method=method, body=body, headers=headers,\n\u001b[1;32m    281\u001b[0m                          \u001b[0mredirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                          connection_type=connection_type)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mnew_request\u001b[0;34m(uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m         resp, content = request(orig_request_method, uri, method, body,\n\u001b[1;32m    174\u001b[0m                                 \u001b[0mclean_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                                 redirections, connection_type)\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# A stored token may expire between the time it is retrieved and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(http, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    280\u001b[0m     return http_callable(uri, method=method, body=body, headers=headers,\n\u001b[1;32m    281\u001b[0m                          \u001b[0mredirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                          connection_type=connection_type)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1924\u001b[0m                         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                         \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                         \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1927\u001b[0m                     )\n\u001b[1;32m   1928\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         (response, content) = self._conn_request(\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m         )\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1531\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 49] Can't assign requested address"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
